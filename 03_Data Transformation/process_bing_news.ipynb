{"cells":[{"cell_type":"code","source":["# Reading the JSON data\n","df = spark.read.option(\"multiline\",\"true\").json(\"Files/bing-latest-news\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":10,"statement_ids":[10],"livy_statement_state":"available","session_id":"2db2290a-4e08-4b02-9351-d84722a1287e","state":"finished","normalized_state":"finished","queued_time":"2024-07-06T14:42:37.2056438Z","session_start_time":null,"execution_start_time":"2024-07-06T14:42:38.1845037Z","execution_finish_time":"2024-07-06T14:42:42.989224Z","parent_msg_id":"d5b2143c-86fd-463f-a49c-744722985658"},"text/plain":"StatementMeta(, 2db2290a-4e08-4b02-9351-d84722a1287e, 10, Finished, Available, Finished)"},"metadata":{}}],"execution_count":8,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"9a44df4f-1bfa-4124-8367-ceb28f3f2ec0"},{"cell_type":"code","source":["# Selecting the 'value' column since it has the required JSON objects as one single row\n","df = df.select('value')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":11,"statement_ids":[11],"livy_statement_state":"available","session_id":"2db2290a-4e08-4b02-9351-d84722a1287e","state":"finished","normalized_state":"finished","queued_time":"2024-07-06T14:42:37.2722202Z","session_start_time":null,"execution_start_time":"2024-07-06T14:42:43.2801077Z","execution_finish_time":"2024-07-06T14:42:43.5086976Z","parent_msg_id":"f72ba9f3-f3d7-430e-95b4-628387f2d220"},"text/plain":"StatementMeta(, 2db2290a-4e08-4b02-9351-d84722a1287e, 11, Finished, Available, Finished)"},"metadata":{}}],"execution_count":9,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9cf2c543-ebee-4083-822f-333de71ffcd7"},{"cell_type":"code","source":["from pyspark.sql.functions import explode\n","import json\n","\n","# Creating a new data frame with 'json_object' column, of which, each row contains a new json object\n","df_exploded = df.select(explode(df['value']).alias('json_object'))\n","\n","\n","# Collecting the JSON objects into a list\n","json_list = df_exploded.toJSON().collect()\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":12,"statement_ids":[12],"livy_statement_state":"available","session_id":"2db2290a-4e08-4b02-9351-d84722a1287e","state":"finished","normalized_state":"finished","queued_time":"2024-07-06T14:42:37.3126157Z","session_start_time":null,"execution_start_time":"2024-07-06T14:42:43.7857394Z","execution_finish_time":"2024-07-06T14:42:48.6185994Z","parent_msg_id":"c41d2f3a-c5af-4b49-b957-eca57fa0e64c"},"text/plain":"StatementMeta(, 2db2290a-4e08-4b02-9351-d84722a1287e, 12, Finished, Available, Finished)"},"metadata":{}}],"execution_count":10,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"69e462fa-64bf-4d4d-b0f5-1fc101654798"},{"cell_type":"code","source":["title = []\n","description = []\n","category = []\n","url = []\n","image = []\n","provider = []\n","datePublished = []\n","\n","for json_str in json_list:\n","    try:\n","        article = json.loads(json_str)\n","\n","        # Checking if 'category' and 'contentUrl' are present in the JSON object\n","        if article[\"json_object\"].get(\"category\") and article[\"json_object\"].get(\"image\",{}).get(\"thumbnail\",{}).get(\"contentUrl\"): \n","            title.append(article['json_object']['name'])\n","            description.append(article['json_object']['description'])\n","            category.append(article['json_object']['category'])\n","            url.append(article['json_object']['url'])\n","            image.append(article['json_object']['image']['thumbnail']['contentUrl'])\n","            provider.append(article['json_object']['provider'] [0]['name'])\n","            datePublished.append(article['json_object']['datePublished'])\n","\n","    except Exception as e:\n","        print(f\"Error processing JSON Object: {e}\")    "],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":13,"statement_ids":[13],"livy_statement_state":"available","session_id":"2db2290a-4e08-4b02-9351-d84722a1287e","state":"finished","normalized_state":"finished","queued_time":"2024-07-06T14:42:37.3712351Z","session_start_time":null,"execution_start_time":"2024-07-06T14:42:48.8997281Z","execution_finish_time":"2024-07-06T14:42:49.1297826Z","parent_msg_id":"cf59352d-2c7f-4f05-b649-d894947e315a"},"text/plain":"StatementMeta(, 2db2290a-4e08-4b02-9351-d84722a1287e, 13, Finished, Available, Finished)"},"metadata":{}}],"execution_count":11,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"32b49220-41c0-4965-8ae2-186f56121ba1"},{"cell_type":"code","source":["from pyspark.sql.types import StructType, StructField, StringType\n","\n","\n","# Create a list of tuples where each tuple contains the respective elements from title, description, category, url, image, provider, and datePublished lists\n","data = list(zip(title,description,category,url,image,provider,datePublished))\n","\n","\n","# Defining the schema for the DataFrame\n","schema = StructType([\n","    StructField(\"title\", StringType(), True),\n","    StructField(\"description\", StringType(), True),\n","    StructField(\"category\", StringType(), True),\n","    StructField(\"url\", StringType(),True),\n","    StructField(\"image\",StringType(), True),\n","    StructField(\"provider\", StringType(), True),\n","    StructField(\"datePublished\", StringType(), True)\n","])\n","\n","# Creating a DataFrame using the data and schema defined above\n","df_cleaned = spark.createDataFrame(data, schema = schema)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":14,"statement_ids":[14],"livy_statement_state":"available","session_id":"2db2290a-4e08-4b02-9351-d84722a1287e","state":"finished","normalized_state":"finished","queued_time":"2024-07-06T14:42:37.4196235Z","session_start_time":null,"execution_start_time":"2024-07-06T14:42:49.4098032Z","execution_finish_time":"2024-07-06T14:42:49.6198517Z","parent_msg_id":"f64829e5-241a-4ea3-a99a-dc834e116483"},"text/plain":"StatementMeta(, 2db2290a-4e08-4b02-9351-d84722a1287e, 14, Finished, Available, Finished)"},"metadata":{}}],"execution_count":12,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"99fc3b76-12df-4041-a2a1-98b4ad989bc2"},{"cell_type":"code","source":["from pyspark.sql.functions import to_date, date_format\n","\n","# Converting the 'datePublished' column to 'dd-MMM-yyyy' format\n","df_cleaned_final = df_cleaned.withColumn(\"datePublished\", date_format(to_date(\"datePublished\"), \"dd-MMM-yyyy\"))"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":15,"statement_ids":[15],"livy_statement_state":"available","session_id":"2db2290a-4e08-4b02-9351-d84722a1287e","state":"finished","normalized_state":"finished","queued_time":"2024-07-06T14:42:37.478056Z","session_start_time":null,"execution_start_time":"2024-07-06T14:42:49.9140478Z","execution_finish_time":"2024-07-06T14:42:50.142136Z","parent_msg_id":"e6376faa-def1-4fad-bcce-f105ebad560e"},"text/plain":"StatementMeta(, 2db2290a-4e08-4b02-9351-d84722a1287e, 15, Finished, Available, Finished)"},"metadata":{}}],"execution_count":13,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5a015274-ad36-4df8-89e8-352bd8326a18"},{"cell_type":"code","source":["from pyspark.sql.utils import AnalysisException\n","\n","try:\n","    table_name = 'bing_lake_db.tbl_latest_news'\n","    df_cleaned_final.write.format(\"delta\").saveAsTable(table_name)\n","\n","except AnalysisException:\n","\n","    print(\"Table already exists\")  \n","\n","    df_cleaned_final.createOrReplaceTempView(\"vw_df_cleaned_final\")\n","\n","    spark.sql(f\"\"\" MERGE INTO {table_name} target_table\n","                   USING vw_df_cleaned_final source_view\n","\n","                   ON source_view.url = target_table.url\n","\n","                   WHEN MATCHED AND\n","                   source_view.title <> target_table.title OR\n","                   source_view.description <> target_table.description OR\n","                   source_view.category <> target_table.category OR\n","                   source_view.image <> target_table.image OR\n","                   source_view.provider <> target_table.provider OR\n","                   source_view.datePublished <> target_table.datePublished \n","\n","                   THEN UPDATE SET * \n","                \n","                \"\"\")  "],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":16,"statement_ids":[16],"livy_statement_state":"available","session_id":"2db2290a-4e08-4b02-9351-d84722a1287e","state":"finished","normalized_state":"finished","queued_time":"2024-07-06T14:42:37.5424241Z","session_start_time":null,"execution_start_time":"2024-07-06T14:42:50.4190666Z","execution_finish_time":"2024-07-06T14:43:06.9506508Z","parent_msg_id":"be0d6aa8-d7fe-4478-904e-b9338aec5b20"},"text/plain":"StatementMeta(, 2db2290a-4e08-4b02-9351-d84722a1287e, 16, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Table already exists\n"]}],"execution_count":14,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f1986e2d-40ae-4d36-8bb7-64500ab1d502"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"synapse_widget":{"version":"0.1","state":{}},"dependencies":{"lakehouse":{"default_lakehouse":"9e808566-937d-421a-a6c3-85b510d85150","default_lakehouse_name":"bing_lake_db","default_lakehouse_workspace_id":"e48cc34f-e9a2-4525-9d15-24188345136c"}}},"nbformat":4,"nbformat_minor":5}